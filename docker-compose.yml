version: '3.9'

services:
  bot:
    image: ghcr.io/0-5788719150923125/bot:latest
    restart: 'always'
    ipc: host
    network_mode: host
    tty: true
    stdin_open: true
    user: 1000:1000
    build:
      context: .
      dockerfile: Dockerfile.${ARCH:-x64}
      shm_size: '1gb'
      args: 
        DCE_VERSION: 2.40.4
        DOTNET_VERSION: 7.0.10
        HUGO_VERSION: 0.118.2
        NODEMON_VERSION: 3.0.1
        NODE_MAJOR_VERSION: 20
        WRANGLER_VERSION: 3.8.0
    volumes:
      - ./book:/book
      - ./gen:/gen
      - ./lab:/lab
      - ./src:/src
    env_file:
      - .env
    environment:
      FOCUS: ${FOCUS:-heart}

  ctx:
    image: ghcr.io/0-5788719150923125/ctx:latest
    restart: 'always'
    network_mode: host

  dash:
    image: ghcr.io/0-5788719150923125/bot:latest
    command: tensorboard --logdir /gen/logs --bind_all --samples_per_plugin scalars=999999999
    volumes:
      - ./gen:/gen
    ports:
      - 6006:6006

  pet:
    image: learningathome/petals:main
    command: python -m petals.cli.run_server bigscience/bloom-560m --public_name "https://src.eco" --cache_dir /src/models --num_blocks 24 --torch_dtype float32
    restart: 'always'
    network_mode: 'host'
    ipc: host
    deploy:
      resources:
        limits:
          cpus: '0.75'
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       capabilities: [gpu]
        #       device_ids: ['1']
    volumes:
      - ./src/models:/src/models
      - ./src/adapters:/src/adapters
    environment:
      HIVEMIND_LOGLEVEL: ERROR

  ipfs:
    image: ipfs/kubo:latest
    command: daemon --init-profile=lowpower
    ports:
      - 9090:8080
    volumes:
      - ./book:/book
      - data:/data/ipfs

volumes:
  data: