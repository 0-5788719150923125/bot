version: '3.9'

services:
  vtx:
    image: ghcr.io/0-5788719150923125/bot:latest
    command: nodemon --ext '*.py, *.yml' --ignore "models/*" --ignore "*.json" --exec python3 main.py
    restart: 'always'
    user: 1000:1000
    ulimits:
      memlock: -1
      stack: 67108864
    build:
      context: .
      dockerfile: Dockerfile
      shm_size: '1gb'
    stdin_open: true
    tty: true
    volumes:
      - ./gen:/gen
      - ./lab:/lab
      - ./vtx:/vtx
    env_file:
      - .env
    environment:
      FOCUS: ${FOCUS:-heart}
      TRANSFORMERS_CACHE: /tmp

  ctx:
    image: ghcr.io/0-5788719150923125/src:latest
    restart: 'always'
    environment:
      CHANNELS: 'hive,support'
      WEBUI: disabled
    ports:
      - 9666:9666

  pit:
    image: ghcr.io/0-5788719150923125/bot:latest
    command: tensorboard --logdir /gen/logs --bind_all --samples_per_plugin scalars=999999999
    volumes:
      - ./gen:/gen
    ports:
      - 6006:6006

  pet:
    image: learningathome/petals:main
    command: python -m petals.cli.run_server bigscience/bloom-7b1-petals --cache_dir /bloom --num_blocks 1 --torch_dtype float32
    restart: 'no'
    network_mode: 'host'
    ipc: host
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 3000M
    volumes:
      - bloom:/bloom

  shm:
    image: tloncorp/vere:live
    command: sh -c "rm -rf /urbit/needle && /bin/urbit -t -c needle"
    restart: 'always'
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 2000M
    ports:
      - 9667:80
      - 34343:34343

volumes:
  bloom:
