version: '3.9'

services:
  vtx:
    image: ghcr.io/0-5788719150923125/src:1
    command: nodemon --ext '*.py, *.yml' --ignore "models/*" --ignore "*.json" --exec python3 main.py
    restart: 'always'
    user: 1000:1000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              # device_ids: ['0']
    ulimits:
      memlock: -1
      stack: 67108864
    build:
      context: .
      dockerfile: Dockerfile
      shm_size: '1gb'
    stdin_open: true
    tty: true
    volumes:
      - ./lab:/lab
      - ./vtx:/vtx
      - ./ctx:/ctx
    env_file:
      - .env
    environment:
      FOCUS: heart
      TRANSFORMERS_CACHE: /tmp

  ctx:
    image: ghcr.io/0-5788719150923125/src:1
    command: npm start
    restart: 'always'
    volumes:
      - ./ctx:/ctx
    ports:
      - 9666:9665

  pet:
    image: learningathome/petals:main
    command: python -m petals.cli.run_server bigscience/bloom-petals --num_blocks 1
    restart: 'no'
    network_mode: 'host'
    ipc: host
    volumes:
      - pet:/cache
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           capabilities: [gpu]

  sos:
    image: ghcr.io/0-5788719150923125/src:1
    command: tensorboard --logdir /lab/logs --bind_all
    volumes:
      - ./lab/logs:/lab/logs
    ports:
      - 6006:6006

  sox:
    image: ipfs/kubo:master-latest
    command: daemon --migrate=true --agent-version-suffix=docker --init-profile=lowpower --writable --enable-gc --enable-pubsub-experiment --enable-namesys-pubsub
    restart: 'always'

volumes:
  pet:
