\begin{table*}[t]
  \begin{center}
    \begin{small}
      \begin{tabular}{l|l}
        \toprule
        \textbf{Original Persona} & \textbf{Revised Persona}\\
        \midrule
I love the beach. & To me, there is nothing like a day at the seashore. \\
My dad has a car dealership & My father sales vehicles for a living. \\
I just got my nails done & I love to pamper myself on a regular basis. \\
I am on a diet now & I need to lose weight. \\
Horses are my favorite animal. &  I am into equestrian sports. \\
\midrule
\ifarxiv
I am an eccentric hair stylist for dogs & I work with animals. \\ %', 'I am a quirky dog groomer ']
My favorite past time is collecting Civil War antiques. & I like finding or buying historical artifacts. \\
I fake a British accent to seem more attractive. & I heard girls liked foreigners.\\
I have been married four times and widowed three. & I have a lot of experience with marriage\\
I have an allergy to mangoes & I have reactions to certain fruits. \\
\midrule
\fi
I play a lot of fantasy videogames. & RPGs are my favorite genre. \\
I have a computer science degree. & I also went to school to work with technology. \\
My mother is a medical doctor & The woman who gave birth to me is a physician. \\
I am very shy. & I am not a social person.\\
I like to build model spaceships.& I enjoy working with my hands. \\
\bottomrule
      \end{tabular}
      \caption{Example Personas (left) and their revised versions (right) from the {\sc persona-chat} dataset.
The revised versions are designed to be characteristics that the same persona might have, which could be rephrases, 
generalizations or specializations.
 \label{table:persona-examples}}
    \end{small}
  \end{center}
\end{table*}


\begin{table*}[t]
  \begin{center}
    \begin{small}
      \begin{tabular}{l|l}
        \toprule
        \textbf{Persona 1} & \textbf{Persona 2}\\
        \midrule
I like to ski & I am an artist\\
My wife does not like me anymore & I have four children\\
I have went to Mexico 4 times this year & I recently got a cat \\
I hate Mexican food &  I enjoy walking for exercise \\
I like to eat cheetos &  I love watching Game of Thrones\\
\bottomrule
\multicolumn{2}{l}{ }\\
\multicolumn{2}{l}{[PERSON 1:] Hi}\\
\multicolumn{2}{l}{[PERSON 2:] Hello ! How are you today ?}\\
\multicolumn{2}{l}{[PERSON 1:] I am good thank you , how are you.}\\
\multicolumn{2}{l}{[PERSON 2:] Great, thanks ! My children and I were just about to watch Game of Thrones. }\\
\multicolumn{2}{l}{[PERSON 1:] Nice ! How old are your children?}\\
\multicolumn{2}{l}{[PERSON 2:] I have four that range in age from 10 to 21. You?}\\
\multicolumn{2}{l}{[PERSON 1:] I do not have children at the moment.}\\ 
\multicolumn{2}{l}{[PERSON 2:] That just means you get to keep all the popcorn for yourself.}\\
\multicolumn{2}{l}{[PERSON 1:] And Cheetos at the moment!}\\
\multicolumn{2}{l}{[PERSON 2:] Good choice. Do you watch Game of Thrones?}\\
\multicolumn{2}{l}{[PERSON 1:] No, I do not have much time for TV.}\\
\multicolumn{2}{l}{[PERSON 2:] I usually spend my time painting: but, I love the show.}\\
      \end{tabular}
      \caption{Example dialog from the {\sc persona-chat} dataset. Person 1 is given their own persona (top left) at the beginning of the chat, but does not know the persona of Person 2, and vice-versa. They have to get to know each other during the conversation.
 \label{table:persona-chat-example}}
    \end{small}
  \end{center}
\end{table*}



\section{The {\sc persona-chat} Dataset} 

The aim of this work is to facilitate more engaging and more personal chit-chat dialogue. The {\sc persona-chat} dataset is a crowd-sourced dataset, collected via Amazon Mechanical Turk, where each of the pair of speakers condition their dialogue on a given profile, which is provided. 
%The dataset and its corresponding data collection source  code, as well as models trained on the data, are all available open source in ParlAI\footnote{\small{\url{http://parl.ai}}}).

The data collection consists of three stages:

%\begin{itemize}

%\item
(i) Personas: we crowdsource a set of 1155 possible personas, each consisting of at least 5 profile sentences, setting aside 100 never seen before personas for validation, and 100 for test.

%\item
(ii) Revised personas: to avoid modeling that takes advantage of trivial word overlap, we crowdsource  additional rewritten sets of the same 1155 personas, with related sentences that are rephrases, generalizations or specializations, rendering the task much more challenging.

(iii) Persona chat: we pair two Turkers and assign them each a random (original) persona from the pool, and ask them to chat. This resulted in a dataset of 162,064 utterances over 10,907 dialogs, 15,602 utterances (1000 dialogs) of which are set aside for validation, and 15,024 utterances
(968 dialogs) for test.

%\end{itemize}

The final dataset and its corresponding data collection source  code, as well as models trained on the data, are all available open source in ParlAI\footnote{ {\small{\url{http://parl.ai}}}}.
%\small\url{https://github.com/facebookresearch/ParlAI/tree/master/projects/personachat}}.


In the following, we describe each data collection stage and the resulting tasks in more detail.

%The final dataset is available in ParlAI\footnote{\url{https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/personachat}}. In the following, we describe each data collection stage in more detail.
%The final dataset will be made publicly available.


\if 0
With this resource, we then consider two tasks which measure the ability of models to engage their dialogue partner in personal conversation:
\begin{itemize}
\item Task 1: Next utterance prediction. Given a dialogue history, predict the next thing to say.  %This can be either conditioned on a profile or 
%One can consider this task either with or without conditioning on known profiles.
\item Task 2: Profile prediction. Given a dialogue history, predict the other speaker's profile.
\end{itemize}

In the following, we describe each data collection stage and the resulting tasks in more detail.
\fi 





\subsection{Personas}

We asked the crowdsourced workers to create a character (persona) description using 5 sentences, providing them only a single example:

{\em ``I am a vegetarian. I like swimming.  My father used to work for Ford.  My favorite band is Maroon5. I got a new job last month, which is about advertising design.''}

Our aim was to create profiles that are natural and descriptive, and contain typical topics of human interest that the speaker 
can bring up in conversation. Because the personas are not the real profiles of the Turkers,
  the dataset does not contain personal information (and they are told specifically not to use any).
We asked the workers to make each sentence short, with a maximum of 15 words per sentence.
This is advantageous both for humans and machines: if they are too long, crowdsourced workers are likely to lose interest, and for machines the task could become more difficult.

Some examples of the  personas collected are given in Table \ref{table:persona-examples} (left).

\subsection{Revised Personas}

A difficulty when constructing dialogue datasets, or text datasets in general, is that in order to
encourage research progress, the task must be carefully constructed so that is neither too
 easy nor too difficult for the current technology 
 \citep{voorhees1999trec}.
One issue with conditioning on textual personas is that there is a danger that humans will, even if asked not to,
unwittingly repeat profile information either verbatim or with significant word overlap.
This may make any subsequent machine learning tasks less challenging, and the solutions will not generalize to
more difficult tasks. This has been a problem in some recent datasets:
for example, the dataset curation technique used for the well-known SQuAD dataset
suffers from this word overlap problem to a certain extent \citep{chen2017reading}.

To alleviate this problem, we presented the original personas we collected to a new set of crowdworkers
and asked them to rewrite the sentences so that a new sentence is about 
{\em ``a related characteristic that the same person may have''},
hence the revisions could be rephrases, generalizations or specializations.
For example {\em ``I like basketball''} can be revised as {\em ``I am a big fan of Michael Jordan''}
not because they mean the same thing but because the same persona could contain both. 

In the revision task, workers are instructed not to trivially rephrase the sentence by copying the original words.
However, during the entry stage if a non-stop word is copied we issue a
warning, and ask them to rephrase, guaranteeing that the instructions are followed. 
For example, {\em ``My father worked for Ford.''} can be revised to
{\em ``My dad worked in the car industry''}, but not
{\em ``My dad was employed by Ford.''} due to word overlap.

\ifarxiv
Finally, we encourage the construction of  natural sentences. In earlier versions of the task we noticed that
the word overlap constraint caused unwanted unnatural constructions such as {\em ``I like eating pretzels''} revised as
{\em ``I like to chew and swallow twisted bread with salt''}. Giving explicit instructions about this seemed to help,
where we prefer a revision like {\em ``I enjoy beers and beer snacks''}.
\fi

Some examples of the revised personas collected are given in Table \ref{table:persona-examples} (right).


\subsection{Persona Chat}\label{personachatter}

After collecting personas, we then collected the dialogues themselves, conditioned on the personas.
For each dialogue, we paired two random crowdworkers, and gave them the instruction that they will chit-chat with another worker, while
playing the part of a given character. We then provide them with a randomly chosen persona from our pool, different to their partners.
The instructions are on purpose quite terse and simply ask them to 
``chat with the other person naturally and try to get to know each other''.
In an early study we noticed the crowdworkers tending to talk about themselves (their own persona) too much, so
we also added the instructions
``both ask questions and answer questions of your chat partner'' which seemed to help.
We also gave a bonus for high quality dialogs.
The dialog is turn-based, with a maximum of 15 words per message.
We again gave instructions to not  trivially copy the character descriptions into the messages,
but also wrote explicit code sending them an error if they tried to do so, using simple string matching.
We define a minimum dialogue length which is randomly between 6 and 8 turns each for each dialogue.
An example dialogue from the dataset is given in Table  \ref{table:persona-chat-example}.


\subsection{Evaluation}

We focus on the standard dialogue task of predicting the next utterance given the dialogue history, but consider this task both with and without the profile information being given to the learning agent. Our goal is to enable interesting directions for future research, where chatbots can for instance have personalities, or imputed personas could be used to make dialogue more engaging to the user.

We consider this in four possible scenarios: conditioning on no persona, your own persona, their persona, or both. These scenarios can be tried using either the original personas, or the revised ones.
We then evaluate the task using three metrics: (i) the log likelihood of the correct sequence, measured via perplexity, (ii) F1 score, and (iii) 
next utterance classification loss, following \newcite{lowe2015ubuntu}.
%Next utterance classification loss 
The latter consists of choosing $N$ random distractor responses from other dialogues (in our setting, $N$=19) and the model selecting the best response among them, resulting in a score of one if the model chooses the correct response, and zero otherwise (called hits@1 in the experiments). %Its main advantage is that it is easy to interpret.

\if 0
As dialogue has many possible responses, leading to a multi-modal distribution of words, word overlap measures do not work well as evaluation metrics \citep{liu2016not,serban2015survey}.
While word level perplexity has many deficiencies as a measure of conversational success, it is standard in more general language modeling, 
and can still capture multi-modal distributions to a certain extent as 
good response word choices should still have high probability.
Thus we include it here.
\fi

\if 0 
\subsection{Persona-Chat Tasks}

The goal of our tasks is to facilitate more engaging and more personal chit-chat dialogue. Our setting naturally leads to two tasks: predicting the next utterance, and predicting the profile of the interlocutor. Both tasks enable interesting directions for future research, where chatbots can for instance have personalities, or imputed personas could be used to make dialogue more engaging to the user. In what follows, we describe the tasks in more detail.

\subsubsection{Next Utterance Prediction}

In the first task, the goal is, given the previous dialogue history and optionally persona information, to generate the response (the next utterance). We thus consider this in four possible scenarios: conditioning on no person, your own persona, their person, or both. We can also try each of these scenarios using either the original personas, or the revised ones.

We evaluate this task using two metrics: (i) the log likelihood of the correct sequence, measured via perplexity and (ii) 
next utterance classification loss, following \cite{lowe2015ubuntu}.

Perplexity is an appealing metric for dialogue as there are many possible responses, leading to a multi-modal distribution of words, which it can still capture as good response word choices should still have high probability. Next utterance classification loss consists of choosing $N$ random distractor responses from other dialogues (in our setting, $N$=19) and choosing the best among them, resulting in a score of one if the model chooses the correct response, and zero otherwise. Its main advantage is that it is easy to interpret.

\subsubsection{Profile Prediction}

In the second task, the goal is, given the agent's own persona and the entire dialogue history as input, to predict the other speaker's persona.

We use the same metrics for evaluating this setting by considering each entry in the other speaker's profile independently as a separate label. We can again consider the evaluation in two settings: using the original personas, or the revised ones. 
\fi
