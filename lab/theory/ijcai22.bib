@InProceedings{Liu_2021_ICCV,
    author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
    title     = {Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {10012-10022}
}

@article{DBLP:journals/corr/abs-2111-06377,
  author    = {Kaiming He and
               Xinlei Chen and
               Saining Xie and
               Yanghao Li and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick},
  title     = {Masked Autoencoders Are Scalable Vision Learners},
  journal   = {CoRR},
  volume    = {abs/2111.06377},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.06377},
  eprinttype = {arXiv},
  eprint    = {2111.06377},
  timestamp = {Tue, 16 Nov 2021 12:12:31 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-06377.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2010-11929,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{Zhao2020CVPR,
author = {Zhao, Hengshuang and Jia, Jiaya and Koltun, Vladlen},
title = {Exploring Self-Attention for Image Recognition},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@InProceedings{pmlr-v139-touvron21a,
  title = 	 {Training data-efficient image transformers-amp; distillation through attention},
  author =       {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jegou, Herve},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {10347--10357},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/touvron21a/touvron21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/touvron21a.html},
  abstract = 	 {Recently, neural networks purely based on attention were shown to address image understanding tasks such as image classification.}
}

@InProceedings{Li_2018_CVPR,
author = {Li, Chen and Zhang, Zhen and Lee, Wee Sun and Lee, Gim Hee},
title = {Convolutional Sequence to Sequence Model for Human Dynamics},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}


@InProceedings{pmlr-v70-gehring17a,
  title = 	 {Convolutional Sequence to Sequence Learning},
  author =       {Jonas Gehring and Michael Auli and David Grangier and Denis Yarats and Yann N. Dauphin},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1243--1252},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/gehring17a/gehring17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/gehring17a.html},
  abstract = 	 {The prevalent approach to sequence to sequence learning maps an input sequence to a variable length output sequence via recurrent neural networks. We introduce an architecture based entirely on convolutional neural networks. Compared to recurrent models, computations over all elements can be fully parallelized during training to better exploit the GPU hardware and optimization is easier since the number of non-linearities is fixed and independent of the input length. Our use of gated linear units eases gradient propagation and we equip each decoder layer with a separate attention module. We outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT’14 English-German and WMT’14 English-French translation at an order of magnitude faster speed, both on GPU and CPU.}
}

@article{DBLP:journals/corr/abs-1901-02860,
  author    = {Zihang Dai and
               Zhilin Yang and
               Yiming Yang and
               Jaime G. Carbonell and
               Quoc V. Le and
               Ruslan Salakhutdinov},
  title     = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
  journal   = {CoRR},
  volume    = {abs/1901.02860},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.02860},
  eprinttype = {arXiv},
  eprint    = {1901.02860},
  timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-02860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1803-02155,
  author    = {Peter Shaw and
               Jakob Uszkoreit and
               Ashish Vaswani},
  title     = {Self-Attention with Relative Position Representations},
  journal   = {CoRR},
  volume    = {abs/1803.02155},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.02155},
  eprinttype = {arXiv},
  eprint    = {1803.02155},
  timestamp = {Mon, 13 Aug 2018 16:46:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-02155.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Wu_2021_ICCV,
    author    = {Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
    title     = {Rethinking and Improving Relative Position Encoding for Vision Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {10033-10041}
}


@InProceedings{pmlr-v119-chen20s,
  title = 	 {Generative Pretraining From Pixels},
  author =       {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1691--1703},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/chen20s/chen20s.pdf},
  url = 	 {https://proceedings.mlr.press/v119/chen20s.html},
  abstract = 	 {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3\% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0\% accuracy with full fine-tuning, matching the top supervised pre-trained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0\% top-1 accuracy on a linear probe of our features.}
}

@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NEURIPS2019_4496bf24,
 author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
 url = {https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf},
 volume = {32},
 year = {2019}
}

@InProceedings{Caron_2021_ICCV,
    author    = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\'egou, Herv\'e and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
    title     = {Emerging Properties in Self-Supervised Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {9650-9660}
}

@InProceedings{He_2020_CVPR,
author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
title = {Momentum Contrast for Unsupervised Visual Representation Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{NEURIPS2020_70feb62b,
 author = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9912--9924},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
 url = {https://proceedings.neurips.cc/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{Chen_2021_ICCV,
    author    = {Chen, Xinlei and Xie, Saining and He, Kaiming},
    title     = {An Empirical Study of Training Self-Supervised Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {9640-9649}
}

@inproceedings{NEURIPS2019_3416a75f,
 author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stand-Alone Self-Attention in Vision Models},
 url = {https://proceedings.neurips.cc/paper/2019/file/3416a75f4cea9109507cacd8e2f2aefc-Paper.pdf},
 volume = {32},
 year = {2019}
}


@InProceedings{Srinivas_2021_CVPR,
    author    = {Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
    title     = {Bottleneck Transformers for Visual Recognition},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {16519-16529}
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{krizhevsky2012imagenet,
title={Imagenet classification with deep convolutional neural networks},
author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
journal={Advances in neural information processing systems},
volume={25},
pages={1097--1105},
year={2012}
}

@article{paszke2019pytorch,
title={Pytorch: An imperative style, high-performance deep learning library},
author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
journal={Advances in neural information processing systems},
volume={32},
pages={8026--8037},
year={2019}
}

@inproceedings{he2019bag,
title={Bag of tricks for image classification with convolutional neural networks},
author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages={558--567},
year={2019}
}

@InProceedings {MaxViT-ref,
author = {Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
title = {MaxViT: Multi-Axis Vision Transformer},
booktitle = { https://arxiv.org/abs/2204.01697},
year = {2022},
month = {04},
}

@inproceedings{zhang2022nested,
  title={Nested hierarchical transformer: Towards accurate, data-efficient and interpretable visual understanding},
  author={Zhang, Zizhao and Zhang, Han and Zhao, Long and Chen, Ting and Arik, Sercan O and Pfister, Tomas},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  volume={2022},
  year={2022}
}

@INPROCEEDINGS{5206848,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}
  
  @article{griffin2007caltech,
  title={Caltech-256 object category dataset},
  author={Griffin, Gregory and Holub, Alex and Perona, Pietro},
  year={2007},
  publisher={California Institute of Technology}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{sameni2022dilemma,
  title={DILEMMA: Self-Supervised Shape and Texture Learning with Transformers},
  author={Sameni, Sepehr and Jenni, Simon and Favaro, Paolo},
  journal={arXiv preprint arXiv:2204.04788},
  year={2022}
}

@article{DBLP:journals/corr/abs-2102-10882,
  author    = {Xiangxiang Chu and
               Bo Zhang and
               Zhi Tian and
               Xiaolin Wei and
               Huaxia Xia},
  title     = {Do We Really Need Explicit Position Encodings for Vision Transformers?},
  journal   = {CoRR},
  volume    = {abs/2102.10882},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.10882},
  eprinttype = {arXiv},
  eprint    = {2102.10882},
  timestamp = {Thu, 12 Aug 2021 15:37:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-10882.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}





