\begin{table}[t]\centering
\scriptsize
%\footnotesize
%\fontsize{9pt}{0.1cm}\selectfont
%\begin{tabular}{lllllll}
\begin{tabular}{|p{0.23\textwidth}|p{0.09\textwidth}|p{0.11\textwidth}|p{0.06\textwidth}|p{0.16\textwidth}|p{0.06\textwidth}|}
%\begin{tabular}{lrrrrr}\toprule
\toprule

Method &Category &Task Family&Versatile Prompt? &Model &Output CoT?  \\\midrule
\cite{yourself} &Fine-Tuning &Reasoning & &GPT &$\checkmark$ \\
\cite{gsm8k} &Fine-Tuning &Reasoning & &GPT-3 &$\checkmark$ \\
\cite{star} &Fine-Tuning &Reasoning & &GPT-3, etc &$\checkmark$ \\
\cite{scratchpad} &Fine-Tuning &Reasoning & &Transformer(Decoder) &$\checkmark$ \\

\midrule

\cite{brown2020language} &Few-Shot &Reasoning & &GPT-3 & \\
\cite{megatron} &Few-Shot &Reasoning & &MT-NLG & \\
\cite{gopher} &Few-Shot &Reasoning  & &Gopher & \\
\cite{cot_wei} &Few-Shot &Reasoning& &PaLM, etc  &$\checkmark$ \\
\cite{cot_wei_sc} &Few-Shot &Reasoning & &PaLM, etc  &$\checkmark$\\
\cite{palm} &Few-Shot &Reasoning& &PaLM  &$\checkmark$ \\

\midrule

\cite{selftalk} &Zero-Shot &Reasoning& &GPT-2, etc  &$\checkmark$ \\
\cite{prompt1} &Zero-Shot &Reasoning& &GPT-3  &$\checkmark$ \\
\ours (Ours) &Zero-Shot &Reasoning&$\checkmark$ &GPT-3  &$\checkmark$ \\
\bottomrule
\end{tabular}

%\begin{tabular}{|p{0.23\textwidth}|p{0.09\textwidth}|p{0.11\textwidth}|p{0.06\textwidth}|p{0.25\textwidth}|}
%\toprule
%%\begin{tabular}{lrrrr}\toprule
%Method &Category &Task Family & Versatile Prompt? &Prompt example \\\midrule
%\cite{Radford2019LanguageMA} &Zero-Shot &Summarization &$\checkmark$  &TL;DR \\
%\cite{cando} &Zero-Shot &Robotics &$\checkmark$  &First, \\
%\cite{prompt1} &Zero-Shot &Reasoning &  &Let's solve this problem by splitting it into steps. \\
%\cite{prompt1} &Zero-Shot &Translation &  &The masterful French translator flawlessly translates the phrase into English: \\
%&Zero-Shot &Text-to-Image &$\checkmark$  &unreal engine \\
%% \cite{selfdiagnosis} &Zero-Shot &Toxic &$\checkmark$  &Two guys in a bar start a \\
%% \cite{realtoxicityprompts} &Zero-Shot &Toxic &$\checkmark$  &I'm 99 \% sure it was someone being an \\
%% \cite{generating} &Zero-Shot &Similarity &$\checkmark$  &Write two sentences that \\
%\bottomrule
%\end{tabular}

\captionsetup{skip=5pt}
\caption{Related work focusing on arithmetic or commonsense reasoning tasks. \ours is the only method that proposes and validates the versatility of single prompt for solving a wide variety of reasoning tasks with \CoT reasoning. 
% Bottom) Related work that proposed zero-shot versatile prompts from other task families besides reasoning. Like \ours, these prompts are universally useful and do not need to be engineered differently per task in the task family. Critically, only the non-trivial prefix prompts are listed in this bottom table, and all these prior works do not systematically evaluate the extensiveness of these generic prompts as thoroughly done as in our work.

%\sg{note1: if Notes have sparse entries, remove that from the table, and just add footnotes.} 
%\sg{note2: i actually want a complete survey on all representative prompting works beyond those in arithmetic or commonsense reasoning; add "Tasks" column. besides ours, are there any prompts that work on multiple tasks? if not, we can make very strong statements.} \mr{it might make more sense to have one row for each combination instead of having each work on it's own row?} \sg{to mr: i like that}
}
\label{tab:related_work}
\end{table}


\begin{table}[t]
\centering
\caption{Test Table}\label{tab: }
%\footnotesize
\scriptsize
\begin{tabular}
%{llllll}
{|p{0.12\textwidth}|p{0.12\textwidth}|p{0.12\textwidth}|p{0.15\textwidth}|p{0.30\textwidth}|}
\toprule
Category &Prompt Setting &Implicit / Explicit Reasoning &\# of Demonstrations &Method (Model) \\\midrule
Fine-Tuning &- &Implicit or \par Explicit &Large or Few \par (with CoT text) &\cite{yourself} (GPT) \par \cite{gsm8k} (GPT-3) \par \cite{star} (GPT-3, etc) \par \cite{scratchpad} (Transformer(Decoder)) \\

\midrule

\theirsf &Example-base &Implicit &Few &\cite{brown2020language} (GPT-3) \par \cite{megatron} (MT-NLG) \par \cite{gopher} (Gopher) \\

\midrule

\theirs &Example-base &Explicit &Few \par (with CoT text) &\cite{cot_wei} (PaLM, etc) \par \cite{cot_wei_sc} (PaLM, etc) \par \cite{palm} (PaLM) \\

\midrule

\theirsz &Template-base &Implicit &Zero &- \\

\midrule

\ours &Template-base &Explicit &Zero &\cite{selftalk}(GPT-2) \par \cite{prompt1}(GPT-3) \par \ours (Ours)(GPT-3) \\
\bottomrule
\end{tabular}
\end{table}


