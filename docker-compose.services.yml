version: '3.9'

services:
  ctx:
    image: ghcr.io/0-5788719150923125/ctx:latest
    restart: 'always'
    network_mode: host
    env_file:
      - .env

  tbd:
    image: ghcr.io/0-5788719150923125/lab:latest
    command: tensorboard --logdir /data/logs --bind_all --samples_per_plugin scalars=999999999
    volumes:
      - ./data:/data
    ports:
      - 6006:6006

  pet:
    image: learningathome/petals:main
    command: python -m petals.cli.run_server bigscience/bloom-560m --public_name "https://src.eco" --cache_dir /data/models --num_blocks 24 --torch_dtype bfloat16
    restart: 'always'
    network_mode: 'host'
    ipc: host
    deploy:
      resources:
        limits:
          cpus: '0.75'
    volumes:
      - ./data/models:/data/models
      - ./data/adapters:/data/adapters
    environment:
      HIVEMIND_LOGLEVEL: ERROR

  fil:
    image: ipfs/kubo:latest
    restart: 'always'
    command: daemon --init-profile=lowpower
    ports:
      - 9090:8080
    volumes:
      - ./book:/book
      - data:/data/ipfs

  # bit:
  #   image: tloncorp/vere
  #   # command: /bin/urbit --loom 31 one
  #   restart: 'always'
  #   stdin_open: true
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.1'
  #         memory: 256MB
  #   volumes:
  #     - ./data/urbit:/urbit
  #   ports:
  #     - 9099:80
  #     - 34343:34343/udp

  # hrd:
  #   image: ghcr.io/haidra-org/ai-horde-worker
  #   env_file:
  #     - .env

volumes:
  data: