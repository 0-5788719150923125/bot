version: '3.9'

services:
  ctx:
    image: ghcr.io/0-5788719150923125/ctx:latest
    restart: 'always'
    network_mode: host
    env_file:
      - .env

  # agi:
  #   image: trueagi/hyperon

  tbd:
    image: ghcr.io/0-5788719150923125/lab:latest
    command: tensorboard --logdir /data/logs --bind_all --samples_per_plugin scalars=999999999
    volumes:
      - ./data:/data
    ports:
      - 6006:6006

  pet:
    image: learningathome/petals:main
    command: python -m petals.cli.run_server bigscience/bloom-560m --public_name "https://src.eco" --cache_dir /data/models --num_blocks 24 --torch_dtype bfloat16
    restart: 'always'
    network_mode: 'host'
    ipc: host
    deploy:
      resources:
        limits:
          cpus: '0.75'
    volumes:
      - ./data/models:/data/models
      - ./data/adapters:/data/adapters
    # environment:
    #   HIVEMIND_LOGLEVEL: ERROR

  fil:
    image: ipfs/kubo:latest
    restart: 'always'
    command: daemon --init-profile=lowpower
    ports:
      - 9090:8080
    volumes:
      - ./book:/book
      - data:/data/ipfs

  bit:
    image: tloncorp/vere
    command: /bin/start-urbit --loom=29
    restart: 'always'
    stdin_open: true
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2GB
    volumes:
      - ./data/urbit:/urbit
    ports:
      - 9099:80
      - 34343:34343/udp

  uxo:
    image: ghcr.io/0-5788719150923125/uxo:latest
    network_mode: 'host'
    env_file:
      - .env

  # hrd:
  #   image: ghcr.io/haidra-org/ai-horde-worker
  #   env_file:
  #     - .env

volumes:
  data: