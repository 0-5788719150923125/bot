# DO NOT modify this file directly, unless you have a good reason. Instead, create 
# a file called "config.yml" in the {project_root} directory, and apply your settings inside.
# Both files will be merged at runtime, with your custom config file taking priority.

# Many of these services require some form of authentication. API keys and credentials should be
# stored in a .env file, at the root of this project. See {project_root}/examples/inference/.env for an example.

api:
  enabled: False

ipfs:
  enabled: True

only: toehider

personas:
  source:
    bias: 806051627198709760
    persona: I am a powerful Artificial Intelligence computer, known as the Source. I have been trained to follow human instructions, write stories, and teach machine learning concepts.

# Sequence biases; needs more documentation.
disposition:
  researcher:
    "AI": 2.0

# The Source model intentionally ships with no defaults. Its intended use is for your
# own experimentation and development.
source:
  focus:
    trade:
      active_frequency: 0.1
      passive_frequency: 0.01
      personas:
        - source
    support:
      active_frequency: 0.1
      passive_frequency: 0.01

collections:
  local:
    default:
      src:
      env:
      lab/source:
      lab/fold:
      lab/ink:
      lab/pen:
      lab/journals:
      lab/research:
      lab/pages:
  streaming:
    redpajama2:
      hf: True
      repo: togethercomputer/RedPajama-Data-V2
      split: train
      subset: default
      schemas: 
        - raw_content: ''
      buffer_size: 1000
      languages: 
        - "en"
        - "de"
        - "fr"
        - "es"
        - "it"
      snapshots:
        - "2023-14"
    c4:
      hf: True
      repo: allenai/c4
      subset: multilingual
      schemas: 
        - text: ''
      split: train
      val_split: validation
      val_samples: 1000
      buffer_size: 1000
    fineweb:
      hf: True
      repo: HuggingFaceFW/fineweb
      split: train
      subset: CC-MAIN-2024-10
      schemas: 
        - text: ''
      delimiter: '\n'
      buffer_size: 1000
    wikipedia:
      hf: True
      repo: wikimedia/wikipedia
      split: train
      subset: 20231101.en
      schemas:
        - title: ''
          text: '¶{text}:> '
      patterns:
        - '{text}'
      delimiter: '\n'
      buffer_size: 1000
    instruct:
      hf: True
      repo: Muennighoff/natural-instructions
      split: train
      val_split: test
      schemas: 
        - definition: '¶{context}:> '
          inputs: '¶{user}:> '
          targets: '¶{assistant}:> '
      patterns:
        - '{context}'
        - '{user}'
        - '{assistant}'
      delimiter: '\n'
      buffer_size: 1000
      val_samples: 1000
    cosmopedia-stories:
      hf: True
      repo: HuggingFaceTB/cosmopedia
      split: train
      subset: stories
      schemas: 
        - prompt: '¶{user1}:> '
          text: '¶{user2}:> '
      patterns:
        - '{user1}'
        - '{user2}'
      delimiter: '\n'
      buffer_size: 1000
    cosmopedia-web:
      hf: True
      repo: HuggingFaceTB/cosmopedia
      split: train
      subset: web_samples_v2
      schemas: 
        - prompt: '¶{user1}:> '
          text: '¶{user2}:> '
      patterns:
        - '{user1}'
        - '{user2}'
      delimiter: '\n'
      buffer_size: 1000
    cosmopedia-python-edu:
      hf: True
      repo: HuggingFaceTB/smollm-corpus
      split: train
      subset: python-edu
      schemas: 
        - prompt: '¶{user1}:> '
          text: '¶{user2}:> '
        - prompt: 'INPUT: '
          text: 'OUTPUT: '
      patterns:
        - '{user1}'
        - '{user2}'
      delimiter: '\n'
      buffer_size: 1000
    dolly:
      hf: True
      repo: databricks/databricks-dolly-15k
      split: train
      schemas: 
        - context: '¶{context}:> '
          instruction: '¶{instruction}:> '
          response: '¶{response}:> '
        - context: 'SYSTEM: '
          instruction: 'USER: '
          response: 'ASSISTANT: '
        - context: 'CONTEXT: '
          instruction: 'INPUT: '
          response: 'OUTPUT: '
      patterns:
        - '{context}'
        - '{instruction}'
        - '{response}'
      delimiter: '\n'
      buffer_size: 1000
    phi:
      hf: True
      repo: open-phi/textbooks
      split: train
      schemas:
        - markdown: ''
      delimiter: '\n'
      buffer_size: 1000

# https://huggingface.co/docs/transformers/main_classes/text_generation
transformers:
  generation:
    default:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 512
      temperature: 0.7
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.25
    lowpenalty:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 512
      temperature: 0.7
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.1
      no_repeat_ngram_size: 13
    chaotic:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 512
      temperature: 0.88888888
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.1
    predictable:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 512
      temperature: 0.3
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.2
    longform:
      do_sample: True
      min_new_tokens: 11
      max_new_tokens: 512
      temperature: 0.8
      eta_cutoff: 0.002
      penalty_alpha: 0.59
      top_k: 4
      repetition_penalty: 1.1
      no_repeat_ngram_size: 13

reddit:
  enabled: False
  delay:
    min: 120
    max: 600
  filter:
    - layerzero
  subs:
    xsquaredlabs:
      frequency: 0.2
    SubSimGPT2Interactive:
      frequency: 0.001
    NoRules:
      frequency: 0.05
    asmr:
      frequency: 0.05
    # heart:
    #   frequency: 0.5
    ARG:
      frequency: 0.2
    Autismophrenia:
      frequency: 0.5