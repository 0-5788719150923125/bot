# DO NOT modify this file directly, unless you have a good reason. Instead, create 
# a file called "config.yml" in the {project_root} directory, and apply your settings inside.
# Both files will be merged at runtime, with your custom config file taking priority.

# Many of these services require some form of authentication. API keys and credentials should be
# stored in a .env file, at the root of this project. See {project_root}/examples/inference/.env for an example.

api:
  enabled: False

ipfs:
  enabled: True

urbit:
  planet: False
  moon: False

only: toehider

personas:
  source:
    bias: 806051627198709760
    persona: I am a powerful Artificial Intelligence computer, known as the Source. I have been trained to follow human instructions, write stories, and teach machine learning concepts.

# Sequence biases; needs more documentation.
disposition:
  researcher:
    "AI": 2.0

# The Source model intentionally ships with no defaults. Its intended use is for your
# own experimentation and development.
source:
  focus:
    trade:
      active_frequency: 0.1
      passive_frequency: 0.01
      personas:
        - source
    support:
      active_frequency: 0.1
      passive_frequency: 0.01

collections:
  static:
    default:
      src:
      env:
      lab/source:
      lab/fold:
      lab/ink:
      lab/pen:
      lab/journals:
      lab/research:
      lab/pages:
  streaming:
    refinedweb:
      repo: tiiuae/falcon-refinedweb
      content_key: content
      buffer_size: 10000
    redpajama2:
      repo: togethercomputer/RedPajama-Data-V2
      content_key: raw_content
      buffer_size: 10000
      snapshots:
        - "2023-14"
      subset: default
      sequential: True
      languages: 
        - "en"
    c4:
      repo: c4
      sequential: True
      subset: en.noblocklist
      content_key: text
      buffer_size: 100000
      val_samples: 1000
    wikitext:
      repo: wikitext
      sequential: True
      subset: wikitext-103-raw-v1
      content_key: text
      buffer_size: 10000
      val_samples: 1000
    instruct:
      repo: Muennighoff/natural-instructions
      buffer_size: 1000
      sample_rate: 0.25
      val_samples: 1000

# https://huggingface.co/docs/transformers/main_classes/text_generation
transformers:
  generation:
    default:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 333
      temperature: 0.9
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.23
    longform:
      do_sample: True
      min_new_tokens: 11
      max_new_tokens: 111
      temperature: 1.1
      eta_cutoff: 0.002
      penalty_alpha: 0.59
      top_k: 4
      repetition_penalty: 1.1
      no_repeat_ngram_size: 9
    lowpenalty:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 333
      temperature: 0.9
      eta_cutoff: 0.002
      penalty_alpha: 0.59
      top_k: 4
      repetition_penalty: 1.1
      no_repeat_ngram_size: 9
    lowestpenalty:
      do_sample: True
      min_new_tokens: 1
      max_new_tokens: 333
      temperature: 0.9
      eta_cutoff: 0.002
      penalty_alpha: 0.6
      top_k: 4
      repetition_penalty: 1.0023
      encoder_repetition_penalty: 0.999

reddit:
  enabled: False
  delay:
    min: 120
    max: 600
  filter:
    - layerzero
  subs:
    xsquaredlabs:
      frequency: 0.2
    SubSimGPT2Interactive:
      frequency: 0.001
    NoRules:
      frequency: 0.05
    asmr:
      frequency: 0.05
    heart:
      frequency: 0.5
    ARG:
      frequency: 0.2
    Autismophrenia:
      frequency: 0.5