frame:
  model: ibm/MoLM-350M-4B
  info: sing with me
  precision: 32
  context_length: 2048
  training:
    type: "pretrain"
    datasets:
      streaming:
        - c4
        - redpajama2
    tokenizer: True
    gradient_checkpointing: True
    prune: 0.0
    optimizer: Lion
    scheduler: cosine
    strategy: hivemind
    initial_piers:
      - /p2p/QmQUeTQh9xjPD4XTGqAhsVN3RGFfrc5NJ75YRGvynHYjFM
    learning_rate: 0.000333
    lookahead: 3
    block_size: 384
    stride: 128
    warmup_steps: 10
    num_steps: 100000
    batch_size: 1
    target_batch_size: 2048
    weight_decay: 0.1
    gradient_clip_val: 1.0
    generate_every: 1
    checkpoint_every: 0
    save_every: 5
    val_interval: 25
    overrides:
      model: Prism
      universal: True
      world_size: 59
      activation_function: silu
      gate_type: gmm
      n_layer: 24
      n_head: 2
      k_att: 5
      k_mlp: 4
      n_att_experts: 60
      n_mlp_experts: 40
      n_ctx: 384 # history_length * n_layer
      n_embd: 256
      gating_size: 4
      block_size: 8
      history_length: 16
      att_hidden: 32
      ffd_hidden: 64
      aux_loss_type: mi
      aux_loss_weight: 0.1
      resid_pdrop: 0.1
      embd_pdrop: 0.23
      attn_pdrop: 0.1
      moe_pdrop: 0.1
      sample_topk: 2
      vocab_size: 12288
      tie_word_embeddings: True